{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitfaaconda182be48403684566abe735bf07221be0",
   "display_name": "Python 3.8.5 64-bit ('FAA': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Practica 2\n",
    "## Diego Rodríguez y Alejandro Jiménez\n",
    "## Grupo 1463"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta,abstractmethod\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Datos import *\n",
    "from EstrategiaParticionado import *\n",
    "from Clasificador import *\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "source": [
    "# Implementación Propia\n",
    "## Tic-tac-toe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error con validación simple sin la place: 0.2945993031358885\n",
      "Error con validación simple sin la place: 0.29463414634146357\n",
      "Error con validación cruzada: 0.3036805555555555\n",
      "Error con validación cruzada: 0.304375\n"
     ]
    }
   ],
   "source": [
    "datos = Datos('./ConjuntoDatos/tic-tac-toe.data')\n",
    "# Validacion simple con 100 iteraciones\n",
    "vs = ValidacionSimple(0.30, 100)\n",
    "# Validación simple con 60 folds\n",
    "vc = ValidacionCruzada(60)\n",
    "# Creación del clasificador\n",
    "nb = ClasificadorNaiveBayes()\n",
    "# Cálculo de errores\n",
    "mio_tic_simple = nb.validacion(vs, {\"nombre\": \"naiveBayes\", \"laplace\": False}, datos)\n",
    "print(\"Error con validación simple sin laplace: \" + str(mio_tic_simple))\n",
    "mio_tic_simple_laplace = nb.validacion(vs, {\"nombre\": \"naiveBayes\", \"laplace\": True}, datos)\n",
    "print(\"Error con validación simple con laplace: \" + str(mio_tic_simple_laplace))\n",
    "mio_tic_cruzada = nb.validacion(vc, {\"nombre\": \"naiveBayes\", \"laplace\": False}, datos)\n",
    "print(\"Error con validación cruzada sin laplace: \" + str(mio_tic_cruzada))\n",
    "mio_tic_cruzada_laplace = nb.validacion(vc, {\"nombre\": \"naiveBayes\", \"laplace\": True}, datos)\n",
    "print(\"Error con validación cruzada con laplace: \" + str(mio_tic_cruzada_laplace))"
   ]
  },
  {
   "source": [
    "## German"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "datos = Datos('./ConjuntoDatos/german.data')\n",
    "# Validacion simple con 20 iteraciones\n",
    "vs = ValidacionSimple(0.30, 20)\n",
    "# Validación simple con 5 folds\n",
    "vc = ValidacionCruzada(5)\n",
    "# Creación del clasificador\n",
    "nb = ClasificadorNaiveBayes()\n",
    "# Cálculo de errores\n",
    "mio_german_simple = nb.validacion(vs, {\"nombre\": \"naiveBayes\", \"laplace\": False}, datos)\n",
    "print(\"Error con validación simple sin laplace: \" + str(mio_tic_simple))\n",
    "mio_german_simple_laplace = nb.validacion(vs, {\"nombre\": \"naiveBayes\", \"laplace\": True}, datos)\n",
    "print(\"Error con validación simple con laplace: \" + str(mio_tic_simple_laplace))\n",
    "mio_german_cruzada = nb.validacion(vc, {\"nombre\": \"naiveBayes\", \"laplace\": False}, datos)\n",
    "print(\"Error con validación cruzada sin laplace: \" + str(mio_tic_cruzada))\n",
    "mio_german_cruzada_laplace = nb.validacion(vc, {\"nombre\": \"naiveBayes\", \"laplace\": True}, datos)\n",
    "print(\"Error con validación cruzada con laplace: \" + str(mio_german_cruzada_laplace))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error con validación simple sin la place: 0.29515679442508713\n",
      "Error con validación simple sin la place: 0.2941114982578398\n",
      "Error con validación cruzada: 0.30576388888888884\n",
      "Error con validación cruzada: 0.30576388888888884\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# Scikit Learn\n",
    "## Tic-tac-toe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "data = pd.read_csv('./ConjuntoDatos/tic-tac-toe.data')\n",
    "\n",
    "# One hot encoding all columns but the class column\n",
    "X_data = pd.get_dummies(data.iloc[:, :-1])\n",
    "Y_data = data.iloc[:, -1]\n",
    "\n",
    "#### Split dataset for simple validation\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X_data, Y_data, test_size=0.3)\n",
    "clf_s = GaussianNB()\n",
    "# Train classifier\n",
    "score = 0\n",
    "part = 1000\n",
    "for _ in range(part):\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(X_data, Y_data, test_size=0.3)\n",
    "    # Train classifier\n",
    "    clf_s.fit(xTrain, yTrain)\n",
    "    # Validate classifier\n",
    "    score += clf_s.score(xTest, yTest)\n",
    "sk_tic_simple = 1 - score / part\n",
    "print(\"Error con validación simple:\" + str(sk_tic_simple))\n",
    "\n",
    "#### Same calculation for cross validation wit 60 folds\n",
    "clf_c = GaussianNB()\n",
    "scores = cross_val_score(clf_c, X_data, Y_data, cv=50)\n",
    "sk_tic_cruzada = (1 - scores).mean()\n",
    "print(\"Error con validación cruzada:\" + str(sk_tic_cruzada))\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error con validación simple:0.32590624999999973\n",
      "Error con validación cruzada:0.3542105263157895\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## German"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error con validación simple:0.28739999999999655\n",
      "Error con validación cruzada:0.2810049019607843\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./ConjuntoDatos/german.data')\n",
    "\n",
    "# One hot encoding all columns but the class column\n",
    "X_data = pd.get_dummies(data.iloc[:, :-1])\n",
    "Y_data = data.iloc[:, -1]\n",
    "\n",
    "clf_s = GaussianNB()\n",
    "\n",
    "score = 0\n",
    "part = 1000\n",
    "for _ in range(part):\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(X_data, Y_data, test_size=0.3)\n",
    "    # Train classifier\n",
    "    clf_s.fit(xTrain, yTrain)\n",
    "    # Validate classifier\n",
    "    score += clf_s.score(xTest, yTest)\n",
    "sk_german_simple = 1 - score / part\n",
    "print(\"Error con validación simple:\" + str(sk_german_simple))\n",
    "\n",
    "#### Same calculation for cross validation wit 60 folds\n",
    "clf_c = GaussianNB()\n",
    "scores = cross_val_score(clf_c, X_data, Y_data, cv=60)\n",
    "sk_german_cruzada = (1 - scores).mean()\n",
    "print(\"Error con validación cruzada:\" + str(sk_german_cruzada))"
   ]
  },
  {
   "source": [
    "# Análisis de resultados\n",
    "Se puede observar que la implementación propia ha obtenido mejores resultados que la obtenida con sklearn.\n",
    "Creemos que esto puede ser debido a que en sklearn hemos usado one hot encoding para pasar convertir los atributos nominales en contínuos. Quizás esta no sea la mejor opción debido a que Naive Bayes asume independencia entre coumnas. Sin embargo, en el caso del Tic Tac Toe, se crearían 3 nuevos atributos por cada atributo primitivo (1 para x, otro para o y otro para b), y estos están claramente relacionados, pues solo 1 de ellos puede ser 1 y el resto deben ser 0.\n",
    "\n",
    "\n",
    "Teniendo en cuenta eso anterior, nuestra hipótesis es que ese error que inducimos en el clasificador más el propio error de el algoritmo Gaussiano causan que el error sea mayor que en el algorítmo implementado por nosotros.\n",
    "\n",
    "Como alternativa a esta implementación en sklearn hay dos que creo que serían más eficaces:\n",
    "\n",
    "1. Utilizar label encoding en vez de one hot encoding. De esta manera eliminaríamos el problema de la relación entre subatributos provenientes de un atributo primitivo. Esta posibilidad creemos que podría funcionar mejor que nuestra implementación. Sin embargo no tenemos seguridad total.\n",
    "\n",
    "2. Utilizar ambos MultinomialNB y GaussianNB: De esta forma se puede entrenar los atributos categóricos con el clasificador multinomial y los continuos con el gausiano. Una vez se tengan calculados se crea una tabla de probabilidades para cada uno de ellos utilizando 'predict_proba' y posterior mente uniendo las 2 matrices de probabilidades en un único dataframe. Lo único que faltaría para concluir sería entrenar un clasificador de Bayes Gaussiano con este último dataframe. De esta forma creemos que se obtendría menor error en la clasificación de variables nominales al principio, pero tampoco sabemos con certeza como afectaría el entrenamiento del clasificador final. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}